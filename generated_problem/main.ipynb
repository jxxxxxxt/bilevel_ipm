{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "\n",
    "from problems.data_generation import generate_problem_data\n",
    "from problems.problem_definition import BilevelProblem\n",
    "from algorithms.barrier_blo_box import BarrierBLO\n",
    "from algorithms.blocc import BLOCC\n",
    "from algorithms.implicit_gradient_descent import IGD\n",
    "from algorithms.BiC_GAFFA import BiC_GAFFA\n",
    "\n",
    "n = 60\n",
    "seed = 9\n",
    "\n",
    "data = generate_problem_data(n, seed)\n",
    "problem = BilevelProblem(data)\n",
    "\n",
    "x_init = np.zeros(n)\n",
    "y_init = np.zeros(n)\n",
    "z_init = np.zeros(problem.num_constraints_h1 + problem.num_constraints_h2)\n",
    "theta_init = np.zeros(n)\n",
    "y_g_init = np.zeros(n)\n",
    "y_F_init = np.zeros(n)\n",
    "mu_g_init = np.zeros(problem.num_constraints_h1 + problem.num_constraints_h2)\n",
    "mu_F_init = np.zeros(problem.num_constraints_h1 + problem.num_constraints_h2)\n",
    "hparams = {\n",
    "        'barrier_blo': {\n",
    "            'M': 0.001,\n",
    "            't': 0.01,\n",
    "            'alpha_x': 0.002,\n",
    "            'alpha_y': 0.1,\n",
    "            'beta_y': 1,\n",
    "            'epsilon_x': 0.1,\n",
    "            'epsilon_y': 0.01,\n",
    "            'inner_max_iters': 1000000,\n",
    "            'outer_max_iters': 100000\n",
    "        },\n",
    "        'blocc': {\n",
    "            'gamma': 100,\n",
    "            'alpha_x': 0.005,\n",
    "            'alpha_g_y': 0.01,\n",
    "            'alpha_F_y': 0.0002,\n",
    "            'beta_g_y': 0.01,\n",
    "            'beta_F_y': 0.01,\n",
    "            'epsilon_x': 0.1,\n",
    "            'epsilon_inner_y_g': 0.01,\n",
    "            'epsilon_outer_y_g': 0.01,\n",
    "            'epsilon_inner_y_F': 0.01,\n",
    "            'epsilon_outer_y_F': 0.01,\n",
    "            'maxmin_g_outer_max_iters': 5000,\n",
    "            'maxmin_F_outer_max_iters': 5000,\n",
    "            'maxmin_g_inner_max_iters': 5000,\n",
    "            'maxmin_F_inner_max_iters': 5000,\n",
    "            'main_max_iters': 5000 \n",
    "        },\n",
    "        'bic_gaffa':{\n",
    "            'alpha':0.01,\n",
    "            'c':1,\n",
    "            'tau':1.3,\n",
    "            'gamma_1':10,\n",
    "            'gamma_2':1,\n",
    "            'eta':1,\n",
    "            'r':1,\n",
    "            'epsilon':0.1,\n",
    "            'max_iters':100\n",
    "        },\n",
    "        'IGD': {\n",
    "            'M': 1e-3,\n",
    "            't': 1e-3,\n",
    "            'alpha_x': 0.001,\n",
    "            'alpha_y': 0.001,\n",
    "            'epsilon_x': 1e-3,\n",
    "            'epsilon_y': 1e-3,\n",
    "            'inner_max_iters': 1000,\n",
    "            'outer_max_iters': 1000\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BiC_GAFFA Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f(x,y)=-25.160383029879597,grad_norm = 79.43628365149956\n",
      "f(x,y)=-26.274633437488433,grad_norm = 15.167974687761916\n",
      "f(x,y)=-26.29272344516163,grad_norm = 1.7689325776616516\n",
      "f(x,y)=-26.29277502778561,grad_norm = 0.0866473914863969\n",
      "f(x,y)=-26.29277509797273,grad_norm = 0.002891309514752457\n",
      "f(x,y)=-26.292775099565418,grad_norm = 0.00039885293459707876\n",
      "f(x,y)=-26.292775099658954,grad_norm = 8.93297876324002e-05\n",
      "f(x,y)=-26.292775099668383,grad_norm = 2.6386357885821548e-05\n",
      "f(x,y)=-26.29277509966976,grad_norm = 9.405170609565252e-06\n",
      "f(x,y)=-26.292775099670028,grad_norm = 3.854748229731183e-06\n",
      "f(x,y)=-26.292775099670088,grad_norm = 1.7625493921787005e-06\n",
      "f(x,y)=-26.292775099670102,grad_norm = 8.80630517946008e-07\n",
      "f(x,y)=-26.292775099670113,grad_norm = 4.735621622798985e-07\n",
      "f(x,y)=-26.29277509967011,grad_norm = 2.7094320608028766e-07\n",
      "f(x,y)=-26.292775099670102,grad_norm = 1.6343842285428162e-07\n",
      "f(x,y)=-26.292775099670123,grad_norm = 1.031877088654911e-07\n",
      "f(x,y)=-26.292775099670116,grad_norm = 6.777864981547974e-08\n",
      "f(x,y)=-26.29277509967011,grad_norm = 4.6086982980062544e-08\n",
      "f(x,y)=-26.292775099670116,grad_norm = 3.2303888571229755e-08\n",
      "f(x,y)=-26.292775099670116,grad_norm = 2.3257644548370895e-08\n",
      "f(x,y)=-26.292775099670116,grad_norm = 1.7146493499406277e-08\n",
      "f(x,y)=-26.292775099670113,grad_norm = 1.2910097569400759e-08\n",
      "f(x,y)=-26.292775099670127,grad_norm = 9.90433228408264e-09\n",
      "f(x,y)=-26.29277509967011,grad_norm = 7.726559207452694e-09\n",
      "f(x,y)=-26.292775099670113,grad_norm = 6.1184781224817905e-09\n",
      "f(x,y)=-26.29277509967011,grad_norm = 4.910432539544648e-09\n",
      "f(x,y)=-26.292775099670113,grad_norm = 3.988564215800266e-09\n",
      "f(x,y)=-26.292775099670116,grad_norm = 3.2749397979016556e-09\n",
      "f(x,y)=-26.29277509967011,grad_norm = 2.715241430843945e-09\n",
      "f(x,y)=-26.29277509967011,grad_norm = 2.2709725630569476e-09\n",
      "f(x,y)=-26.292775099670106,grad_norm = 1.9144263803037916e-09\n",
      "f(x,y)=-26.292775099670113,grad_norm = 1.6253745436692304e-09\n",
      "f(x,y)=-26.29277509967011,grad_norm = 1.3888523067496692e-09\n",
      "f(x,y)=-26.292775099670102,grad_norm = 1.1936497566504722e-09\n",
      "f(x,y)=-26.29277509967011,grad_norm = 1.031273991668167e-09\n",
      "f(x,y)=-26.29277509967011,grad_norm = 8.952206240564916e-10\n",
      "f(x,y)=-26.292775099670106,grad_norm = 7.804566998145866e-10\n",
      "f(x,y)=-26.292775099670102,grad_norm = 6.83052349065338e-10\n",
      "f(x,y)=-26.292775099670116,grad_norm = 5.999103490121359e-10\n",
      "f(x,y)=-26.292775099670116,grad_norm = 5.285698777590357e-10\n",
      "f(x,y)=-26.292775099670116,grad_norm = 4.670595396595455e-10\n",
      "f(x,y)=-26.29277509967011,grad_norm = 4.1378889052445344e-10\n",
      "f(x,y)=-26.29277509967011,grad_norm = 3.6746493611743927e-10\n",
      "f(x,y)=-26.292775099670116,grad_norm = 3.270302717196398e-10\n",
      "f(x,y)=-26.292775099670113,grad_norm = 2.916136377790602e-10\n",
      "f(x,y)=-26.292775099670102,grad_norm = 2.6049371141006556e-10\n",
      "f(x,y)=-26.29277509967011,grad_norm = 2.3306914091921045e-10\n",
      "f(x,y)=-26.292775099670116,grad_norm = 2.0883641926208769e-10\n",
      "f(x,y)=-26.29277509967011,grad_norm = 1.8737122814512683e-10\n",
      "f(x,y)=-26.292775099670116,grad_norm = 1.683146654209874e-10\n",
      "f(x,y)=-26.29277509967011,grad_norm = 1.5136149088244577e-10\n",
      "f(x,y)=-26.29277509967012,grad_norm = 1.362509446000356e-10\n",
      "f(x,y)=-26.292775099670102,grad_norm = 1.227594493172486e-10\n",
      "f(x,y)=-26.29277509967011,grad_norm = 1.1069434720178172e-10\n",
      "f(x,y)=-26.292775099670116,grad_norm = 9.988926074859554e-11\n",
      "f(x,y)=-26.292775099670106,grad_norm = 9.019976531399123e-11\n",
      "f(x,y)=-26.29277509967011,grad_norm = 8.150012162769612e-11\n",
      "f(x,y)=-26.29277509967011,grad_norm = 7.368061885029812e-11\n",
      "f(x,y)=-26.292775099670113,grad_norm = 6.664505741968906e-11\n",
      "f(x,y)=-26.292775099670123,grad_norm = 6.030906504356849e-11\n",
      "f(x,y)=-26.29277509967011,grad_norm = 5.459826130309676e-11\n",
      "f(x,y)=-26.292775099670116,grad_norm = 4.94470006705619e-11\n",
      "f(x,y)=-26.29277509967011,grad_norm = 4.4797210183108276e-11\n",
      "f(x,y)=-26.292775099670102,grad_norm = 4.0597402140747166e-11\n",
      "f(x,y)=-26.29277509967011,grad_norm = 3.680182063657497e-11\n",
      "f(x,y)=-26.292775099670106,grad_norm = 3.336974830525267e-11\n",
      "f(x,y)=-26.29277509967011,grad_norm = 3.0264869133213477e-11\n",
      "f(x,y)=-26.292775099670116,grad_norm = 2.7454758405684282e-11\n",
      "f(x,y)=-26.292775099670113,grad_norm = 2.4910419489297308e-11\n",
      "f(x,y)=-26.29277509967011,grad_norm = 2.2605866827350173e-11\n",
      "f(x,y)=-26.292775099670116,grad_norm = 2.0517820233075944e-11\n",
      "f(x,y)=-26.292775099670113,grad_norm = 1.862535345292181e-11\n",
      "f(x,y)=-26.292775099670116,grad_norm = 1.6909688257447736e-11\n",
      "f(x,y)=-26.292775099670113,grad_norm = 1.5353915783568816e-11\n",
      "f(x,y)=-26.29277509967011,grad_norm = 1.3942808964592476e-11\n",
      "f(x,y)=-26.292775099670113,grad_norm = 1.2662651578616761e-11\n",
      "f(x,y)=-26.292775099670116,grad_norm = 1.1501074721425908e-11\n",
      "f(x,y)=-26.292775099670113,grad_norm = 1.0446917089664948e-11\n",
      "f(x,y)=-26.292775099670116,grad_norm = 9.490086695901972e-12\n",
      "f(x,y)=-26.292775099670113,grad_norm = 8.621481638315414e-12\n",
      "f(x,y)=-26.29277509967011,grad_norm = 7.832863031542788e-12\n",
      "f(x,y)=-26.29277509967011,grad_norm = 7.116779262031688e-12\n",
      "f(x,y)=-26.29277509967011,grad_norm = 6.466492129339805e-12\n",
      "f(x,y)=-26.29277509967012,grad_norm = 5.875897582904756e-12\n",
      "f(x,y)=-26.29277509967012,grad_norm = 5.339467113469239e-12\n",
      "f(x,y)=-26.29277509967011,grad_norm = 4.85219769573365e-12\n",
      "f(x,y)=-26.292775099670106,grad_norm = 4.409548753700614e-12\n",
      "f(x,y)=-26.29277509967011,grad_norm = 4.007408051137959e-12\n",
      "f(x,y)=-26.29277509967011,grad_norm = 3.642046858889026e-12\n",
      "f(x,y)=-26.292775099670106,grad_norm = 3.3100831392925106e-12\n",
      "f(x,y)=-26.292775099670116,grad_norm = 3.0084483189472626e-12\n",
      "f(x,y)=-26.292775099670113,grad_norm = 2.7343603762337798e-12\n",
      "f(x,y)=-26.292775099670116,grad_norm = 2.4852927594089256e-12\n",
      "f(x,y)=-26.292775099670113,grad_norm = 2.2589523447502877e-12\n",
      "f(x,y)=-26.292775099670116,grad_norm = 2.053258412986133e-12\n",
      "f(x,y)=-26.292775099670113,grad_norm = 1.8663220455755297e-12\n",
      "f(x,y)=-26.292775099670116,grad_norm = 1.6964278889928405e-12\n",
      "f(x,y)=-26.292775099670116,grad_norm = 1.5420186519347675e-12\n",
      "f(x,y)=-26.292775099670102,grad_norm = 1.401679190142774e-12\n",
      "f(x,y)=-26.29277509967011,grad_norm = 1.2741250493077366e-12\n",
      "-26.29277509967011\n"
     ]
    }
   ],
   "source": [
    "bic_algo = BiC_GAFFA(problem, hparams)\n",
    "\n",
    "x_opt_bic, y_opt_bic, history = bic_algo.bic_gaffa(x_init, y_init, z_init, theta_init)\n",
    "print(problem.f(x_opt_bic, y_opt_bic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BiC_GAFFA Feasibility Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_theoretical_opt_result=56.96459582870526, f_blocc_numerical_result=-26.29277509967011\n",
      "g_theoretical_opt_result=-48.53645524012808, g_blocc_numerical_result=0.0\n",
      "h_1[0] = -0.22763474112308701\n",
      "h_1[1] = -0.8779064257387715\n",
      "h_1[2] = -0.5339547027139351\n",
      "h_1[3] = -0.35116317302613753\n",
      "h_1[4] = -0.2871273405685729\n",
      "h_1[5] = -0.02584656083667536\n",
      "h_1[6] = -0.8602919490571069\n",
      "h_1[7] = -0.6838406791631587\n",
      "h_1[8] = -0.2892123596437677\n",
      "h_1[9] = -0.9657110970341924\n",
      "h_1[10] = -0.1722560534396942\n",
      "h_1[11] = -0.3077636987611079\n",
      "h_1[12] = -0.37786382086100334\n",
      "h_1[13] = -0.8831616191677\n",
      "h_1[14] = -0.6853745312971752\n",
      "h_1[15] = -0.3535801796315752\n",
      "h_1[16] = -0.4083224434398852\n",
      "h_1[17] = -0.35555446061126583\n",
      "h_1[18] = -0.8660479913457553\n",
      "h_1[19] = -0.043299747458223736\n",
      "h_2[0] = -1.0\n",
      "h_2[1] = -1.0\n",
      "h_2[2] = -1.0\n",
      "h_2[3] = -1.0\n",
      "h_2[4] = -1.0\n",
      "h_2[5] = -1.0\n",
      "h_2[6] = -1.0\n",
      "h_2[7] = -1.0\n",
      "h_2[8] = -1.0\n",
      "h_2[9] = -1.0\n",
      "h_2[10] = -1.0\n",
      "h_2[11] = -1.0\n",
      "h_2[12] = -1.0\n",
      "h_2[13] = -1.0\n",
      "h_2[14] = -1.0\n",
      "h_2[15] = -1.0\n",
      "h_2[16] = -1.0\n",
      "h_2[17] = -1.0\n",
      "h_2[18] = -1.0\n",
      "h_2[19] = -1.0\n",
      "h_2[20] = -1.0\n",
      "h_2[21] = -1.0\n",
      "h_2[22] = -1.0\n",
      "h_2[23] = -1.0\n",
      "h_2[24] = -1.0\n",
      "h_2[25] = -1.0\n",
      "h_2[26] = -1.0\n",
      "h_2[27] = -1.0\n",
      "h_2[28] = -1.0\n",
      "h_2[29] = -1.0\n",
      "h_2[30] = -1.0\n",
      "h_2[31] = -1.0\n",
      "h_2[32] = -1.0\n",
      "h_2[33] = -1.0\n",
      "h_2[34] = -1.0\n",
      "h_2[35] = -1.0\n",
      "h_2[36] = -1.0\n",
      "h_2[37] = -1.0\n",
      "h_2[38] = -1.0\n",
      "h_2[39] = -1.0\n",
      "h_2[40] = -1.0\n",
      "h_2[41] = -1.0\n",
      "h_2[42] = -1.0\n",
      "h_2[43] = -1.0\n",
      "h_2[44] = -1.0\n",
      "h_2[45] = -1.0\n",
      "h_2[46] = -1.0\n",
      "h_2[47] = -1.0\n",
      "h_2[48] = -1.0\n",
      "h_2[49] = -1.0\n",
      "h_2[50] = -1.0\n",
      "h_2[51] = -1.0\n",
      "h_2[52] = -1.0\n",
      "h_2[53] = -1.0\n",
      "h_2[54] = -1.0\n",
      "h_2[55] = -1.0\n",
      "h_2[56] = -1.0\n",
      "h_2[57] = -1.0\n",
      "h_2[58] = -1.0\n",
      "h_2[59] = -1.0\n",
      "h_2[60] = -1.0\n",
      "h_2[61] = -1.0\n",
      "h_2[62] = -1.0\n",
      "h_2[63] = -1.0\n",
      "h_2[64] = -1.0\n",
      "h_2[65] = -1.0\n",
      "h_2[66] = -1.0\n",
      "h_2[67] = -1.0\n",
      "h_2[68] = -1.0\n",
      "h_2[69] = -1.0\n",
      "h_2[70] = -1.0\n",
      "h_2[71] = -1.0\n",
      "h_2[72] = -1.0\n",
      "h_2[73] = -1.0\n",
      "h_2[74] = -1.0\n",
      "h_2[75] = -1.0\n",
      "h_2[76] = -1.0\n",
      "h_2[77] = -1.0\n",
      "h_2[78] = -1.0\n",
      "h_2[79] = -1.0\n",
      "h_2[80] = -1.0\n",
      "h_2[81] = -1.0\n",
      "h_2[82] = -1.0\n",
      "h_2[83] = -1.0\n",
      "h_2[84] = -1.0\n",
      "h_2[85] = -1.0\n",
      "h_2[86] = -1.0\n",
      "h_2[87] = -1.0\n",
      "h_2[88] = -1.0\n",
      "h_2[89] = -1.0\n",
      "h_2[90] = -1.0\n",
      "h_2[91] = -1.0\n",
      "h_2[92] = -1.0\n",
      "h_2[93] = -1.0\n",
      "h_2[94] = -1.0\n",
      "h_2[95] = -1.0\n",
      "h_2[96] = -1.0\n",
      "h_2[97] = -1.0\n",
      "h_2[98] = -1.0\n",
      "h_2[99] = -1.0\n",
      "h_2[100] = -1.0\n",
      "h_2[101] = -1.0\n",
      "h_2[102] = -1.0\n",
      "h_2[103] = -1.0\n",
      "h_2[104] = -1.0\n",
      "h_2[105] = -1.0\n",
      "h_2[106] = -1.0\n",
      "h_2[107] = -1.0\n",
      "h_2[108] = -1.0\n",
      "h_2[109] = -1.0\n",
      "h_2[110] = -1.0\n",
      "h_2[111] = -1.0\n",
      "h_2[112] = -1.0\n",
      "h_2[113] = -1.0\n",
      "h_2[114] = -1.0\n",
      "h_2[115] = -1.0\n",
      "h_2[116] = -1.0\n",
      "h_2[117] = -1.0\n",
      "h_2[118] = -1.0\n",
      "h_2[119] = -1.0\n"
     ]
    }
   ],
   "source": [
    "barrier_algo = BarrierBLO(problem, hparams)\n",
    "\n",
    "h1_values = [problem.h_1(x_opt_bic, y_opt_bic, i) for i in range(problem.num_constraints_h1)]\n",
    "h2_values = [problem.h_2(x_opt_bic, y_opt_bic, i) for i in range(problem.num_constraints_h2)]\n",
    "\n",
    "y_original_opt_blocc = barrier_algo.Interior_inner_loop(x_opt_bic, y_opt_bic)\n",
    "print(f\"f_theoretical_opt_result={problem.f(x_opt_bic, y_original_opt_blocc)}, f_blocc_numerical_result={problem.f(x_opt_bic, y_opt_bic)}\")\n",
    "\n",
    "print(f\"g_theoretical_opt_result={problem.g(x_opt_bic, y_original_opt_blocc)}, g_blocc_numerical_result={problem.g(x_opt_bic, y_opt_bic)}\")\n",
    "\n",
    "for i, h_val in enumerate(h1_values):\n",
    "    print(f\"h_1[{i}] = {h_val}\")\n",
    "\n",
    "for i, h_val in enumerate(h2_values):\n",
    "    print(f\"h_2[{i}] = {h_val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BLOCC Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main iteration 1\n",
      "Inner iter for L_g=0, Projected Gradient norm w.r.t y of L_g=77.81704153080214\n",
      "Inner iter for L_g=1, Projected Gradient norm w.r.t y of L_g=31.767444706447122\n",
      "Inner iter for L_g=2, Projected Gradient norm w.r.t y of L_g=13.466603359198848\n",
      "Inner iter for L_g=3, Projected Gradient norm w.r.t y of L_g=5.877338960259464\n",
      "Inner iter for L_g=4, Projected Gradient norm w.r.t y of L_g=2.6228919389201626\n",
      "Inner iter for L_g=5, Projected Gradient norm w.r.t y of L_g=1.1907891827373167\n",
      "Inner iter for L_g=6, Projected Gradient norm w.r.t y of L_g=0.547899178382287\n",
      "Inner iter for L_g=7, Projected Gradient norm w.r.t y of L_g=0.2547703192424772\n",
      "Inner iter for L_g=8, Projected Gradient norm w.r.t y of L_g=0.1194667142495143\n",
      "Inner iter for L_g=9, Projected Gradient norm w.r.t y of L_g=0.05640002810274485\n",
      "Inner iter for L_g=10, Projected Gradient norm w.r.t y of L_g=0.02677275502985416\n",
      "Inner iter for L_g=11, Projected Gradient norm w.r.t y of L_g=0.012766121044104642\n",
      "Inner loop for L_g converges when iter = 12\n",
      "Outer loop for L_g converges when iter = 0\n",
      "Inner iter for L_F=0, Projected Gradient norm w.r.t y of L_F=169.56542713690177\n",
      "Inner iter for L_F=1, Projected Gradient norm w.r.t y of L_F=38.621875516789885\n",
      "Inner iter for L_F=2, Projected Gradient norm w.r.t y of L_F=11.988563009533117\n",
      "Inner iter for L_F=3, Projected Gradient norm w.r.t y of L_F=4.32314756010132\n",
      "Inner iter for L_F=4, Projected Gradient norm w.r.t y of L_F=1.6986143064300323\n",
      "Inner iter for L_F=5, Projected Gradient norm w.r.t y of L_F=0.6995893396104526\n",
      "Inner iter for L_F=6, Projected Gradient norm w.r.t y of L_F=0.29553430072078224\n",
      "Inner iter for L_F=7, Projected Gradient norm w.r.t y of L_F=0.12659470541832218\n",
      "Inner iter for L_F=8, Projected Gradient norm w.r.t y of L_F=0.05465977633215225\n",
      "Inner iter for L_F=9, Projected Gradient norm w.r.t y of L_F=0.023712453387272278\n",
      "Inner iter for L_F=10, Projected Gradient norm w.r.t y of L_F=0.010317429838399209\n",
      "Inner loop for L_F converges when iter = 11\n",
      "Outer loop for L_F converges when iter = 0\n",
      "f(x,y)=75.72813894242398,grad_norm = 76.57832140294022\n",
      "Main iteration 2\n",
      "Inner iter for L_g=0, Projected Gradient norm w.r.t y of L_g=27.182924154034136\n",
      "Inner iter for L_g=1, Projected Gradient norm w.r.t y of L_g=2.0882947331426953\n",
      "Inner iter for L_g=2, Projected Gradient norm w.r.t y of L_g=0.8663327649291188\n",
      "Inner iter for L_g=3, Projected Gradient norm w.r.t y of L_g=0.3745598177287754\n",
      "Inner iter for L_g=4, Projected Gradient norm w.r.t y of L_g=0.16722019634099008\n",
      "Inner iter for L_g=5, Projected Gradient norm w.r.t y of L_g=0.07643496232708957\n",
      "Inner iter for L_g=6, Projected Gradient norm w.r.t y of L_g=0.035534578005107224\n",
      "Inner iter for L_g=7, Projected Gradient norm w.r.t y of L_g=0.01672261103548305\n",
      "Inner loop for L_g converges when iter = 8\n",
      "Outer loop for L_g converges when iter = 0\n",
      "Inner iter for L_F=0, Projected Gradient norm w.r.t y of L_F=155.69941900639478\n",
      "Inner iter for L_F=1, Projected Gradient norm w.r.t y of L_F=34.639371131998395\n",
      "Inner iter for L_F=2, Projected Gradient norm w.r.t y of L_F=10.049491119104372\n",
      "Inner iter for L_F=3, Projected Gradient norm w.r.t y of L_F=3.3284358301682104\n",
      "Inner iter for L_F=4, Projected Gradient norm w.r.t y of L_F=1.205391032796114\n",
      "Inner iter for L_F=5, Projected Gradient norm w.r.t y of L_F=0.46256943665251915\n",
      "Inner iter for L_F=6, Projected Gradient norm w.r.t y of L_F=0.1838667173780449\n",
      "Inner iter for L_F=7, Projected Gradient norm w.r.t y of L_F=0.07461117352565913\n",
      "Inner iter for L_F=8, Projected Gradient norm w.r.t y of L_F=0.030645788996641863\n",
      "Inner iter for L_F=9, Projected Gradient norm w.r.t y of L_F=0.012679307746360419\n",
      "Inner loop for L_F converges when iter = 10\n",
      "Outer loop for L_F converges when iter = 0\n",
      "f(x,y)=60.04785488543153,grad_norm = 30.733066038701075\n",
      "Main iteration 3\n",
      "Inner iter for L_g=0, Projected Gradient norm w.r.t y of L_g=12.31291565323732\n",
      "Inner iter for L_g=1, Projected Gradient norm w.r.t y of L_g=1.0732407974680305\n",
      "Inner iter for L_g=2, Projected Gradient norm w.r.t y of L_g=0.43904659983086003\n",
      "Inner iter for L_g=3, Projected Gradient norm w.r.t y of L_g=0.18629039118653193\n",
      "Inner iter for L_g=4, Projected Gradient norm w.r.t y of L_g=0.08155917843792017\n",
      "Inner iter for L_g=5, Projected Gradient norm w.r.t y of L_g=0.036626531446234116\n",
      "Inner iter for L_g=6, Projected Gradient norm w.r.t y of L_g=0.016779250342902383\n",
      "Inner loop for L_g converges when iter = 7\n",
      "Outer loop for L_g converges when iter = 0\n",
      "Inner iter for L_F=0, Projected Gradient norm w.r.t y of L_F=149.88976433631876\n",
      "Inner iter for L_F=1, Projected Gradient norm w.r.t y of L_F=33.50572298063491\n",
      "Inner iter for L_F=2, Projected Gradient norm w.r.t y of L_F=9.70844770256587\n",
      "Inner iter for L_F=3, Projected Gradient norm w.r.t y of L_F=3.1811975555264347\n",
      "Inner iter for L_F=4, Projected Gradient norm w.r.t y of L_F=1.132080256501468\n",
      "Inner iter for L_F=5, Projected Gradient norm w.r.t y of L_F=0.4263654456766205\n",
      "Inner iter for L_F=6, Projected Gradient norm w.r.t y of L_F=0.1666821367840873\n",
      "Inner iter for L_F=7, Projected Gradient norm w.r.t y of L_F=0.06672825476087269\n",
      "Inner iter for L_F=8, Projected Gradient norm w.r.t y of L_F=0.027115643445816295\n",
      "Inner iter for L_F=9, Projected Gradient norm w.r.t y of L_F=0.011123621460957469\n",
      "Inner loop for L_F converges when iter = 10\n",
      "Outer loop for L_F converges when iter = 0\n",
      "f(x,y)=53.33745499132152,grad_norm = 13.874461315170013\n",
      "Main iteration 4\n",
      "Inner iter for L_g=0, Projected Gradient norm w.r.t y of L_g=4.628315319916957\n",
      "Inner iter for L_g=1, Projected Gradient norm w.r.t y of L_g=0.8677521527533282\n",
      "Inner iter for L_g=2, Projected Gradient norm w.r.t y of L_g=0.3713964761521904\n",
      "Inner iter for L_g=3, Projected Gradient norm w.r.t y of L_g=0.16292376109119222\n",
      "Inner iter for L_g=4, Projected Gradient norm w.r.t y of L_g=0.0729659897913991\n",
      "Inner iter for L_g=5, Projected Gradient norm w.r.t y of L_g=0.033227202579381096\n",
      "Inner iter for L_g=6, Projected Gradient norm w.r.t y of L_g=0.015330068264279633\n",
      "Inner loop for L_g converges when iter = 7\n",
      "Outer loop for L_g converges when iter = 0\n",
      "Inner iter for L_F=0, Projected Gradient norm w.r.t y of L_F=149.47223562553515\n",
      "Inner iter for L_F=1, Projected Gradient norm w.r.t y of L_F=33.43561926856218\n",
      "Inner iter for L_F=2, Projected Gradient norm w.r.t y of L_F=9.681128179581153\n",
      "Inner iter for L_F=3, Projected Gradient norm w.r.t y of L_F=3.1631409299729345\n",
      "Inner iter for L_F=4, Projected Gradient norm w.r.t y of L_F=1.1218604142634365\n",
      "Inner iter for L_F=5, Projected Gradient norm w.r.t y of L_F=0.4212454222050158\n",
      "Inner iter for L_F=6, Projected Gradient norm w.r.t y of L_F=0.16427850600585042\n",
      "Inner iter for L_F=7, Projected Gradient norm w.r.t y of L_F=0.06563866016713901\n",
      "Inner iter for L_F=8, Projected Gradient norm w.r.t y of L_F=0.026631617700544372\n",
      "Inner iter for L_F=9, Projected Gradient norm w.r.t y of L_F=0.010911340342551284\n",
      "Inner loop for L_F converges when iter = 10\n",
      "Outer loop for L_F converges when iter = 0\n",
      "f(x,y)=52.09983408488116,grad_norm = 5.658326984178958\n",
      "Main iteration 5\n",
      "Inner iter for L_g=0, Projected Gradient norm w.r.t y of L_g=2.155776012043159\n",
      "Inner iter for L_g=1, Projected Gradient norm w.r.t y of L_g=0.6737148360517077\n",
      "Inner iter for L_g=2, Projected Gradient norm w.r.t y of L_g=0.28751941156804556\n",
      "Inner iter for L_g=3, Projected Gradient norm w.r.t y of L_g=0.12566798166657228\n",
      "Inner iter for L_g=4, Projected Gradient norm w.r.t y of L_g=0.056056583375904474\n",
      "Inner iter for L_g=5, Projected Gradient norm w.r.t y of L_g=0.02542431917099898\n",
      "Inner iter for L_g=6, Projected Gradient norm w.r.t y of L_g=0.011683782696155784\n",
      "Inner loop for L_g converges when iter = 7\n",
      "Outer loop for L_g converges when iter = 0\n",
      "Inner iter for L_F=0, Projected Gradient norm w.r.t y of L_F=149.56472183333173\n",
      "Inner iter for L_F=1, Projected Gradient norm w.r.t y of L_F=33.44963622823715\n",
      "Inner iter for L_F=2, Projected Gradient norm w.r.t y of L_F=9.679411891545051\n",
      "Inner iter for L_F=3, Projected Gradient norm w.r.t y of L_F=3.158717607397078\n",
      "Inner iter for L_F=4, Projected Gradient norm w.r.t y of L_F=1.1188621520310962\n",
      "Inner iter for L_F=5, Projected Gradient norm w.r.t y of L_F=0.4196701359737054\n",
      "Inner iter for L_F=6, Projected Gradient norm w.r.t y of L_F=0.1635264902049652\n",
      "Inner iter for L_F=7, Projected Gradient norm w.r.t y of L_F=0.06529483670110621\n",
      "Inner iter for L_F=8, Projected Gradient norm w.r.t y of L_F=0.026477911233876043\n",
      "Inner iter for L_F=9, Projected Gradient norm w.r.t y of L_F=0.010843547208213086\n",
      "Inner loop for L_F converges when iter = 10\n",
      "Outer loop for L_F converges when iter = 0\n",
      "f(x,y)=51.915736434701515,grad_norm = 2.341233463144896\n",
      "Main iteration 6\n",
      "Inner iter for L_g=0, Projected Gradient norm w.r.t y of L_g=1.626109453009135\n",
      "Inner iter for L_g=1, Projected Gradient norm w.r.t y of L_g=0.6296776431930627\n",
      "Inner iter for L_g=2, Projected Gradient norm w.r.t y of L_g=0.2678818600109347\n",
      "Inner iter for L_g=3, Projected Gradient norm w.r.t y of L_g=0.1166874946069702\n",
      "Inner iter for L_g=4, Projected Gradient norm w.r.t y of L_g=0.05186422288050163\n",
      "Inner iter for L_g=5, Projected Gradient norm w.r.t y of L_g=0.02343772614342981\n",
      "Inner iter for L_g=6, Projected Gradient norm w.r.t y of L_g=0.010732837619161426\n",
      "Inner loop for L_g converges when iter = 7\n",
      "Outer loop for L_g converges when iter = 0\n",
      "Inner iter for L_F=0, Projected Gradient norm w.r.t y of L_F=149.6634466915426\n",
      "Inner iter for L_F=1, Projected Gradient norm w.r.t y of L_F=33.46700101441755\n",
      "Inner iter for L_F=2, Projected Gradient norm w.r.t y of L_F=9.680816636502902\n",
      "Inner iter for L_F=3, Projected Gradient norm w.r.t y of L_F=3.157357671385682\n",
      "Inner iter for L_F=4, Projected Gradient norm w.r.t y of L_F=1.1177737777225143\n",
      "Inner iter for L_F=5, Projected Gradient norm w.r.t y of L_F=0.4190849179413653\n",
      "Inner iter for L_F=6, Projected Gradient norm w.r.t y of L_F=0.16324732967946928\n",
      "Inner iter for L_F=7, Projected Gradient norm w.r.t y of L_F=0.06516784700343019\n",
      "Inner iter for L_F=8, Projected Gradient norm w.r.t y of L_F=0.026421393439481022\n",
      "Inner iter for L_F=9, Projected Gradient norm w.r.t y of L_F=0.01081869004079606\n",
      "Inner loop for L_F converges when iter = 10\n",
      "Outer loop for L_F converges when iter = 0\n",
      "f(x,y)=51.92828060293489,grad_norm = 0.9867554956022474\n",
      "Main iteration 7\n",
      "Inner iter for L_g=0, Projected Gradient norm w.r.t y of L_g=1.514242453602755\n",
      "Inner iter for L_g=1, Projected Gradient norm w.r.t y of L_g=0.6177607706743233\n",
      "Inner iter for L_g=2, Projected Gradient norm w.r.t y of L_g=0.26263513565343716\n",
      "Inner iter for L_g=3, Projected Gradient norm w.r.t y of L_g=0.1142954844463163\n",
      "Inner iter for L_g=4, Projected Gradient norm w.r.t y of L_g=0.050740303683953936\n",
      "Inner iter for L_g=5, Projected Gradient norm w.r.t y of L_g=0.022898215346492418\n",
      "Inner iter for L_g=6, Projected Gradient norm w.r.t y of L_g=0.010470456637186078\n",
      "Inner loop for L_g converges when iter = 7\n",
      "Outer loop for L_g converges when iter = 0\n",
      "Inner iter for L_F=0, Projected Gradient norm w.r.t y of L_F=149.7267826170538\n",
      "Inner iter for L_F=1, Projected Gradient norm w.r.t y of L_F=33.4775081065569\n",
      "Inner iter for L_F=2, Projected Gradient norm w.r.t y of L_F=9.681763479459494\n",
      "Inner iter for L_F=3, Projected Gradient norm w.r.t y of L_F=3.1567842989998094\n",
      "Inner iter for L_F=4, Projected Gradient norm w.r.t y of L_F=1.1172988868615998\n",
      "Inner iter for L_F=5, Projected Gradient norm w.r.t y of L_F=0.4188329842407325\n",
      "Inner iter for L_F=6, Projected Gradient norm w.r.t y of L_F=0.16312927568987876\n",
      "Inner iter for L_F=7, Projected Gradient norm w.r.t y of L_F=0.06511497592392973\n",
      "Inner iter for L_F=8, Projected Gradient norm w.r.t y of L_F=0.02639813714513432\n",
      "Inner iter for L_F=9, Projected Gradient norm w.r.t y of L_F=0.01080854145435344\n",
      "Inner loop for L_F converges when iter = 10\n",
      "Outer loop for L_F converges when iter = 0\n",
      "f(x,y)=51.96521928580855,grad_norm = 0.42388510867959445\n",
      "Main iteration 8\n",
      "Inner iter for L_g=0, Projected Gradient norm w.r.t y of L_g=1.4862820712944256\n",
      "Inner iter for L_g=1, Projected Gradient norm w.r.t y of L_g=0.6133374142432247\n",
      "Inner iter for L_g=2, Projected Gradient norm w.r.t y of L_g=0.2607235583747228\n",
      "Inner iter for L_g=3, Projected Gradient norm w.r.t y of L_g=0.1134344089371018\n",
      "Inner iter for L_g=4, Projected Gradient norm w.r.t y of L_g=0.05033752847332285\n",
      "Inner iter for L_g=5, Projected Gradient norm w.r.t y of L_g=0.022704605199346365\n",
      "Inner iter for L_g=6, Projected Gradient norm w.r.t y of L_g=0.010375850394890758\n",
      "Inner loop for L_g converges when iter = 7\n",
      "Outer loop for L_g converges when iter = 0\n",
      "Inner iter for L_F=0, Projected Gradient norm w.r.t y of L_F=149.76215237516448\n",
      "Inner iter for L_F=1, Projected Gradient norm w.r.t y of L_F=33.482733484034725\n",
      "Inner iter for L_F=2, Projected Gradient norm w.r.t y of L_F=9.68211333837609\n",
      "Inner iter for L_F=3, Projected Gradient norm w.r.t y of L_F=3.156463800228827\n",
      "Inner iter for L_F=4, Projected Gradient norm w.r.t y of L_F=1.1170587392032947\n",
      "Inner iter for L_F=5, Projected Gradient norm w.r.t y of L_F=0.41871042659940216\n",
      "Inner iter for L_F=6, Projected Gradient norm w.r.t y of L_F=0.16307333450888925\n",
      "Inner iter for L_F=7, Projected Gradient norm w.r.t y of L_F=0.06509041403050303\n",
      "Inner iter for L_F=8, Projected Gradient norm w.r.t y of L_F=0.0263874902650083\n",
      "Inner iter for L_F=9, Projected Gradient norm w.r.t y of L_F=0.010803942186693363\n",
      "Inner loop for L_F converges when iter = 10\n",
      "Outer loop for L_F converges when iter = 0\n",
      "f(x,y)=51.992844006047285,grad_norm = 0.1852667925688271\n",
      "Main iteration 9\n",
      "Inner iter for L_g=0, Projected Gradient norm w.r.t y of L_g=1.4775413012851397\n",
      "Inner iter for L_g=1, Projected Gradient norm w.r.t y of L_g=0.611304730788061\n",
      "Inner iter for L_g=2, Projected Gradient norm w.r.t y of L_g=0.2598461884713917\n",
      "Inner iter for L_g=3, Projected Gradient norm w.r.t y of L_g=0.1130405965973074\n",
      "Inner iter for L_g=4, Projected Gradient norm w.r.t y of L_g=0.05015416362648888\n",
      "Inner iter for L_g=5, Projected Gradient norm w.r.t y of L_g=0.022616863035043972\n",
      "Inner iter for L_g=6, Projected Gradient norm w.r.t y of L_g=0.01033314508867492\n",
      "Inner loop for L_g converges when iter = 7\n",
      "Outer loop for L_g converges when iter = 0\n",
      "Inner iter for L_F=0, Projected Gradient norm w.r.t y of L_F=149.78037576652397\n",
      "Inner iter for L_F=1, Projected Gradient norm w.r.t y of L_F=33.485039645524544\n",
      "Inner iter for L_F=2, Projected Gradient norm w.r.t y of L_F=9.682158122988534\n",
      "Inner iter for L_F=3, Projected Gradient norm w.r.t y of L_F=3.156263652370337\n",
      "Inner iter for L_F=4, Projected Gradient norm w.r.t y of L_F=1.1169273089258338\n",
      "Inner iter for L_F=5, Projected Gradient norm w.r.t y of L_F=0.4186461397947871\n",
      "Inner iter for L_F=6, Projected Gradient norm w.r.t y of L_F=0.1630446922168602\n",
      "Inner iter for L_F=7, Projected Gradient norm w.r.t y of L_F=0.06507805201055006\n",
      "Inner iter for L_F=8, Projected Gradient norm w.r.t y of L_F=0.026382199868442896\n",
      "Inner iter for L_F=9, Projected Gradient norm w.r.t y of L_F=0.010801678019937547\n",
      "Inner loop for L_F converges when iter = 10\n",
      "Outer loop for L_F converges when iter = 0\n",
      "Main loop converged at iteration 8\n",
      "52.00837229744439\n"
     ]
    }
   ],
   "source": [
    "blocc_algo = BLOCC(problem, hparams)\n",
    "\n",
    "\n",
    "x_opt_blocc, y_opt_blocc, history = blocc_algo.blocc(x_init, y_g_init, y_F_init, mu_g_init, mu_F_init)\n",
    "print(problem.f(x_opt_blocc, y_opt_blocc))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BLOCC Feasibility Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_theoretical_opt_result=55.7499439284052, f_blocc_numerical_result=52.00837229744439\n",
      "g_theoretical_opt_result=-47.29700898498122, g_blocc_numerical_result=-47.2784833279084\n",
      "h_1[0] = -1.278292590992046\n",
      "h_1[1] = -0.4283731804923677\n",
      "h_1[2] = 2.220446049250313e-16\n",
      "h_1[3] = 5.551115123125783e-17\n",
      "h_1[4] = -0.47419381499427393\n",
      "h_1[5] = -0.05873411556606156\n",
      "h_1[6] = -0.6585673170732038\n",
      "h_1[7] = -3.3306690738754696e-16\n",
      "h_1[8] = -0.9992363969505241\n",
      "h_1[9] = -1.0577634966243086\n",
      "h_1[10] = -8.326672684688674e-17\n",
      "h_1[11] = -1.3825592388539134\n",
      "h_1[12] = -0.33384351151720015\n",
      "h_1[13] = -1.4748649660857212\n",
      "h_1[14] = -1.4511374636608712\n",
      "h_1[15] = -0.06445563202772092\n",
      "h_1[16] = -0.3359472617496754\n",
      "h_1[17] = 1.1102230246251565e-16\n",
      "h_1[18] = -0.589338760535262\n",
      "h_1[19] = -5.551115123125783e-17\n",
      "h_2[0] = -1.076720586797243\n",
      "h_2[1] = -1.020143996480367\n",
      "h_2[2] = -0.9712837176051434\n",
      "h_2[3] = -1.0594659465016099\n",
      "h_2[4] = -1.0871526826375233\n",
      "h_2[5] = -0.8247985459414764\n",
      "h_2[6] = -1.021433200508073\n",
      "h_2[7] = -1.1599324057217757\n",
      "h_2[8] = -1.351530159949392\n",
      "h_2[9] = -1.1295162034596635\n",
      "h_2[10] = -1.0235623356656232\n",
      "h_2[11] = -1.0254584596717395\n",
      "h_2[12] = -1.132146512372999\n",
      "h_2[13] = -0.8824213737689559\n",
      "h_2[14] = -0.9142560621784998\n",
      "h_2[15] = -0.7292090996706199\n",
      "h_2[16] = -0.8361098077241051\n",
      "h_2[17] = -1.0938401127145096\n",
      "h_2[18] = -0.763125340790354\n",
      "h_2[19] = -1.255873506129047\n",
      "h_2[20] = -1.1467834342656835\n",
      "h_2[21] = -1.1498327750281572\n",
      "h_2[22] = -1.0120016917105226\n",
      "h_2[23] = -1.2251831353690854\n",
      "h_2[24] = -0.8353849553672198\n",
      "h_2[25] = -0.9595521517026921\n",
      "h_2[26] = -1.2474177076282067\n",
      "h_2[27] = -0.9315818436135227\n",
      "h_2[28] = -0.7787033913777205\n",
      "h_2[29] = -1.2481108158921137\n",
      "h_2[30] = -0.9072631505397306\n",
      "h_2[31] = -1.119555236349641\n",
      "h_2[32] = -0.8803197545709242\n",
      "h_2[33] = -0.7513776449400076\n",
      "h_2[34] = -1.1302833295099597\n",
      "h_2[35] = -0.8546206336233217\n",
      "h_2[36] = -1.078079007236774\n",
      "h_2[37] = -1.1079330885377316\n",
      "h_2[38] = -1.1487727308816167\n",
      "h_2[39] = -0.8433995774114906\n",
      "h_2[40] = -0.869743375650332\n",
      "h_2[41] = -1.0150124712355715\n",
      "h_2[42] = -1.2164901008435478\n",
      "h_2[43] = -0.8704299299124212\n",
      "h_2[44] = -1.3070529958961117\n",
      "h_2[45] = -1.2663055155413143\n",
      "h_2[46] = -0.8849101446455112\n",
      "h_2[47] = -0.9506759607507783\n",
      "h_2[48] = -1.0652634265901035\n",
      "h_2[49] = -1.2495418846317399\n",
      "h_2[50] = -1.0971034440418626\n",
      "h_2[51] = -0.84179141685142\n",
      "h_2[52] = -1.002536364445963\n",
      "h_2[53] = -1.1369771065592797\n",
      "h_2[54] = -1.0637112180737371\n",
      "h_2[55] = -0.9226782819007388\n",
      "h_2[56] = -1.0670999367347656\n",
      "h_2[57] = -0.9956037037473643\n",
      "h_2[58] = -0.8250490011771683\n",
      "h_2[59] = -0.8793260892505929\n",
      "h_2[60] = -0.9232794132027571\n",
      "h_2[61] = -0.9798560035196331\n",
      "h_2[62] = -1.0287162823948566\n",
      "h_2[63] = -0.9405340534983901\n",
      "h_2[64] = -0.9128473173624768\n",
      "h_2[65] = -1.1752014540585236\n",
      "h_2[66] = -0.9785667994919269\n",
      "h_2[67] = -0.8400675942782243\n",
      "h_2[68] = -0.6484698400506079\n",
      "h_2[69] = -0.8704837965403365\n",
      "h_2[70] = -0.9764376643343767\n",
      "h_2[71] = -0.9745415403282603\n",
      "h_2[72] = -0.867853487627001\n",
      "h_2[73] = -1.117578626231044\n",
      "h_2[74] = -1.0857439378215001\n",
      "h_2[75] = -1.2707909003293802\n",
      "h_2[76] = -1.1638901922758949\n",
      "h_2[77] = -0.9061598872854904\n",
      "h_2[78] = -1.236874659209646\n",
      "h_2[79] = -0.7441264938709532\n",
      "h_2[80] = -0.8532165657343164\n",
      "h_2[81] = -0.8501672249718427\n",
      "h_2[82] = -0.9879983082894773\n",
      "h_2[83] = -0.7748168646309146\n",
      "h_2[84] = -1.16461504463278\n",
      "h_2[85] = -1.0404478482973079\n",
      "h_2[86] = -0.7525822923717933\n",
      "h_2[87] = -1.0684181563864774\n",
      "h_2[88] = -1.2212966086222796\n",
      "h_2[89] = -0.7518891841078863\n",
      "h_2[90] = -1.0927368494602694\n",
      "h_2[91] = -0.880444763650359\n",
      "h_2[92] = -1.119680245429076\n",
      "h_2[93] = -1.2486223550599924\n",
      "h_2[94] = -0.8697166704900403\n",
      "h_2[95] = -1.1453793663766783\n",
      "h_2[96] = -0.9219209927632258\n",
      "h_2[97] = -0.8920669114622684\n",
      "h_2[98] = -0.8512272691183834\n",
      "h_2[99] = -1.1566004225885094\n",
      "h_2[100] = -1.1302566243496681\n",
      "h_2[101] = -0.9849875287644285\n",
      "h_2[102] = -0.7835098991564522\n",
      "h_2[103] = -1.1295700700875788\n",
      "h_2[104] = -0.6929470041038883\n",
      "h_2[105] = -0.7336944844586857\n",
      "h_2[106] = -1.1150898553544888\n",
      "h_2[107] = -1.0493240392492216\n",
      "h_2[108] = -0.9347365734098964\n",
      "h_2[109] = -0.75045811536826\n",
      "h_2[110] = -0.9028965559581373\n",
      "h_2[111] = -1.15820858314858\n",
      "h_2[112] = -0.997463635554037\n",
      "h_2[113] = -0.8630228934407203\n",
      "h_2[114] = -0.9362887819262629\n",
      "h_2[115] = -1.0773217180992611\n",
      "h_2[116] = -0.9329000632652344\n",
      "h_2[117] = -1.0043962962526356\n",
      "h_2[118] = -1.1749509988228317\n",
      "h_2[119] = -1.120673910749407\n"
     ]
    }
   ],
   "source": [
    "barrier_algo = BarrierBLO(problem, hparams)\n",
    "\n",
    "h1_values = [problem.h_1(x_opt_blocc, y_opt_blocc, i) for i in range(problem.num_constraints_h1)]\n",
    "h2_values = [problem.h_2(x_opt_blocc, y_opt_blocc, i) for i in range(problem.num_constraints_h2)]\n",
    "\n",
    "y_original_opt_blocc = barrier_algo.Interior_inner_loop(x_opt_blocc, y_opt_blocc)\n",
    "print(f\"f_theoretical_opt_result={problem.f(x_opt_blocc, y_original_opt_blocc)}, f_blocc_numerical_result={problem.f(x_opt_blocc, y_opt_blocc)}\")\n",
    "\n",
    "print(f\"g_theoretical_opt_result={problem.g(x_opt_blocc, y_original_opt_blocc)}, g_blocc_numerical_result={problem.g(x_opt_blocc, y_opt_blocc)}\")\n",
    "\n",
    "for i, h_val in enumerate(h1_values):\n",
    "    print(f\"h_1[{i}] = {h_val}\")\n",
    "\n",
    "for i, h_val in enumerate(h2_values):\n",
    "    print(f\"h_2[{i}] = {h_val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implicit Gradient Descent Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer iteration 1\n",
      "Inner loop converged at iteration 200\n",
      "f(x, y) = 95.45037851360806, grad_norm = 76.59673418115331\n",
      "Outer iteration 2\n",
      "Inner loop converged at iteration 112\n",
      "f(x, y) = 91.19500851740221, grad_norm = 67.2257525452191\n",
      "Outer iteration 3\n",
      "Inner loop converged at iteration 110\n",
      "f(x, y) = 87.9160198480594, grad_norm = 59.00630049516197\n",
      "Outer iteration 4\n",
      "Inner loop converged at iteration 107\n",
      "f(x, y) = 85.39015297241798, grad_norm = 51.796437571852486\n",
      "Outer iteration 5\n",
      "Inner loop converged at iteration 105\n",
      "f(x, y) = 83.44417540097366, grad_norm = 45.471557030758525\n",
      "Outer iteration 6\n",
      "Inner loop converged at iteration 102\n",
      "f(x, y) = 81.94475905747844, grad_norm = 39.922553604489096\n",
      "Outer iteration 7\n",
      "Inner loop converged at iteration 100\n",
      "f(x, y) = 80.7892951506114, grad_norm = 35.053784045327106\n",
      "Outer iteration 8\n",
      "Inner loop converged at iteration 98\n",
      "f(x, y) = 79.8987827656407, grad_norm = 30.781487703596458\n",
      "Outer iteration 9\n",
      "Inner loop converged at iteration 95\n",
      "f(x, y) = 79.2123918992656, grad_norm = 27.032266927597973\n",
      "Outer iteration 10\n",
      "Inner loop converged at iteration 93\n",
      "f(x, y) = 78.68329448643124, grad_norm = 23.74175894039358\n",
      "Outer iteration 11\n",
      "Inner loop converged at iteration 90\n",
      "f(x, y) = 78.27540350382259, grad_norm = 20.853608163737235\n",
      "Outer iteration 12\n",
      "Inner loop converged at iteration 88\n",
      "f(x, y) = 77.96094198300462, grad_norm = 18.318363676827598\n",
      "Outer iteration 13\n",
      "Inner loop converged at iteration 86\n",
      "f(x, y) = 77.71849405679437, grad_norm = 16.0927179912185\n",
      "Outer iteration 14\n",
      "Inner loop converged at iteration 83\n",
      "f(x, y) = 77.53155519383614, grad_norm = 14.13870427727054\n",
      "Outer iteration 15\n",
      "Inner loop converged at iteration 81\n",
      "f(x, y) = 77.38742558035138, grad_norm = 12.422994282621938\n",
      "Outer iteration 16\n",
      "Inner loop converged at iteration 78\n",
      "f(x, y) = 77.27629175348399, grad_norm = 10.916418822862822\n",
      "Outer iteration 17\n",
      "Inner loop converged at iteration 76\n",
      "f(x, y) = 77.1906145853767, grad_norm = 9.593344383119149\n",
      "Outer iteration 18\n",
      "Inner loop converged at iteration 74\n",
      "f(x, y) = 77.12456326411956, grad_norm = 8.431331459880218\n",
      "Outer iteration 19\n",
      "Inner loop converged at iteration 71\n",
      "f(x, y) = 77.07363942610112, grad_norm = 7.410699054643763\n",
      "Outer iteration 20\n",
      "Inner loop converged at iteration 69\n",
      "f(x, y) = 77.03439599026451, grad_norm = 6.5141425891706275\n",
      "Outer iteration 21\n",
      "Inner loop converged at iteration 67\n",
      "f(x, y) = 77.00415514223099, grad_norm = 5.72652275772915\n",
      "Outer iteration 22\n",
      "Inner loop converged at iteration 65\n",
      "f(x, y) = 76.98085710202743, grad_norm = 5.034544306389758\n",
      "Outer iteration 23\n",
      "Inner loop converged at iteration 62\n",
      "f(x, y) = 76.96290515510672, grad_norm = 4.426555395323482\n",
      "Outer iteration 24\n",
      "Inner loop converged at iteration 60\n",
      "f(x, y) = 76.94908976122963, grad_norm = 3.892291274496778\n",
      "Outer iteration 25\n",
      "Inner loop converged at iteration 58\n",
      "f(x, y) = 76.93845815482294, grad_norm = 3.4227841157167793\n",
      "Outer iteration 26\n",
      "Inner loop converged at iteration 56\n",
      "f(x, y) = 76.93028081925299, grad_norm = 3.0101507320052683\n",
      "Outer iteration 27\n",
      "Inner loop converged at iteration 53\n",
      "f(x, y) = 76.92398694451714, grad_norm = 2.647485273308358\n",
      "Outer iteration 28\n",
      "Inner loop converged at iteration 51\n",
      "f(x, y) = 76.91915856164644, grad_norm = 2.328685413904667\n",
      "Outer iteration 29\n",
      "Inner loop converged at iteration 49\n",
      "f(x, y) = 76.91545362437573, grad_norm = 2.048433541930085\n",
      "Outer iteration 30\n",
      "Inner loop converged at iteration 47\n",
      "f(x, y) = 76.912613490868, grad_norm = 1.802049001610457\n",
      "Outer iteration 31\n",
      "Inner loop converged at iteration 45\n",
      "f(x, y) = 76.91043898263231, grad_norm = 1.5854215684217998\n",
      "Outer iteration 32\n",
      "Inner loop converged at iteration 43\n",
      "f(x, y) = 76.90877652280301, grad_norm = 1.394942035521362\n",
      "Outer iteration 33\n",
      "Inner loop converged at iteration 41\n",
      "f(x, y) = 76.90750770182483, grad_norm = 1.2274408877332188\n",
      "Outer iteration 34\n",
      "Inner loop converged at iteration 39\n",
      "f(x, y) = 76.90654124276887, grad_norm = 1.0801344969588729\n",
      "Outer iteration 35\n",
      "Inner loop converged at iteration 37\n",
      "f(x, y) = 76.90580680170186, grad_norm = 0.9505779311143441\n",
      "Outer iteration 36\n",
      "Inner loop converged at iteration 35\n",
      "f(x, y) = 76.90525018263696, grad_norm = 0.8366235611450941\n",
      "Outer iteration 37\n",
      "Inner loop converged at iteration 33\n",
      "f(x, y) = 76.90482964383747, grad_norm = 0.7363847507100247\n",
      "Outer iteration 38\n",
      "Inner loop converged at iteration 31\n",
      "f(x, y) = 76.90451304616118, grad_norm = 0.6482040018185098\n",
      "Outer iteration 39\n",
      "Inner loop converged at iteration 29\n",
      "f(x, y) = 76.90427565102429, grad_norm = 0.5706250074532475\n",
      "Outer iteration 40\n",
      "Inner loop converged at iteration 27\n",
      "f(x, y) = 76.9040984193842, grad_norm = 0.5023681303351434\n",
      "Outer iteration 41\n",
      "Inner loop converged at iteration 26\n",
      "f(x, y) = 76.90397478891757, grad_norm = 0.44229534388939384\n",
      "Outer iteration 42\n",
      "Inner loop converged at iteration 24\n",
      "f(x, y) = 76.90387961114493, grad_norm = 0.3894438718816097\n",
      "Outer iteration 43\n",
      "Inner loop converged at iteration 22\n",
      "f(x, y) = 76.90380874087796, grad_norm = 0.3429352371415336\n",
      "Outer iteration 44\n",
      "Inner loop converged at iteration 21\n",
      "f(x, y) = 76.90376447060599, grad_norm = 0.3019908167963335\n",
      "Outer iteration 45\n",
      "Inner loop converged at iteration 19\n",
      "f(x, y) = 76.90372888546715, grad_norm = 0.2659633708394716\n",
      "Outer iteration 46\n",
      "Inner loop converged at iteration 18\n",
      "f(x, y) = 76.903709558148, grad_norm = 0.2342413249552539\n",
      "Outer iteration 47\n",
      "Inner loop converged at iteration 16\n",
      "f(x, y) = 76.903692064481, grad_norm = 0.2063272530262727\n",
      "Outer iteration 48\n",
      "Inner loop converged at iteration 15\n",
      "f(x, y) = 76.90368519817181, grad_norm = 0.18174419311137502\n",
      "Outer iteration 49\n",
      "Inner loop converged at iteration 13\n",
      "f(x, y) = 76.90367623028797, grad_norm = 0.16011159991615626\n",
      "Outer iteration 50\n",
      "Inner loop converged at iteration 12\n",
      "f(x, y) = 76.90367447931366, grad_norm = 0.1410566239163635\n",
      "Outer iteration 51\n",
      "Inner loop converged at iteration 11\n",
      "f(x, y) = 76.90367623494241, grad_norm = 0.12427547175024709\n",
      "Outer iteration 52\n",
      "Inner loop converged at iteration 10\n",
      "f(x, y) = 76.90367957813928, grad_norm = 0.109497606985133\n",
      "Outer iteration 53\n",
      "Inner loop converged at iteration 9\n",
      "f(x, y) = 76.90368340243421, grad_norm = 0.09648387501508207\n",
      "Outer iteration 54\n",
      "Inner loop converged at iteration 8\n",
      "f(x, y) = 76.90368699110326, grad_norm = 0.08502347307695289\n",
      "Outer iteration 55\n",
      "Inner loop converged at iteration 7\n",
      "f(x, y) = 76.90368981806722, grad_norm = 0.07493082035797054\n",
      "Outer iteration 56\n",
      "Inner loop converged at iteration 7\n",
      "f(x, y) = 76.90369930884346, grad_norm = 0.06602940393428679\n",
      "Outer iteration 57\n",
      "Inner loop converged at iteration 6\n",
      "f(x, y) = 76.9037050198536, grad_norm = 0.05819473632237999\n",
      "Outer iteration 58\n",
      "Inner loop converged at iteration 5\n",
      "f(x, y) = 76.9037077133738, grad_norm = 0.051297344145820434\n",
      "Outer iteration 59\n",
      "Inner loop converged at iteration 4\n",
      "f(x, y) = 76.90370759624356, grad_norm = 0.045224631165828345\n",
      "Outer iteration 60\n",
      "Inner loop converged at iteration 4\n",
      "f(x, y) = 76.9037124646029, grad_norm = 0.039864922651547764\n",
      "Outer iteration 61\n",
      "Inner loop converged at iteration 3\n",
      "f(x, y) = 76.90371294904179, grad_norm = 0.03514927852885797\n",
      "Outer iteration 62\n",
      "Inner loop converged at iteration 3\n",
      "f(x, y) = 76.903717257973, grad_norm = 0.03098683457824924\n",
      "Outer iteration 63\n",
      "Inner loop converged at iteration 3\n",
      "f(x, y) = 76.90372424663977, grad_norm = 0.027313933760215823\n",
      "Outer iteration 64\n",
      "Inner loop converged at iteration 2\n",
      "f(x, y) = 76.90372556461588, grad_norm = 0.02408616896528856\n",
      "Outer iteration 65\n",
      "Inner loop converged at iteration 2\n",
      "f(x, y) = 76.90372939859306, grad_norm = 0.02123666543275678\n",
      "Outer iteration 66\n",
      "Inner loop converged at iteration 1\n",
      "f(x, y) = 76.90372752208205, grad_norm = 0.018734108912134267\n",
      "Outer iteration 67\n",
      "Inner loop converged at iteration 1\n",
      "f(x, y) = 76.90372791770815, grad_norm = 0.016523866772518537\n",
      "Outer iteration 68\n",
      "Inner loop converged at iteration 1\n",
      "f(x, y) = 76.90373013868275, grad_norm = 0.014572116251667338\n",
      "Outer iteration 69\n",
      "Inner loop converged at iteration 1\n",
      "f(x, y) = 76.90373380368686, grad_norm = 0.012848911728708988\n",
      "Outer iteration 70\n",
      "Inner loop converged at iteration 0\n",
      "f(x, y) = 76.90373088501268, grad_norm = 0.011340217198545874\n",
      "Outer iteration 71\n",
      "Inner loop converged at iteration 1\n",
      "f(x, y) = 76.90373719710088, grad_norm = 0.009994672133838688\n",
      "Outer iteration 72\n",
      "Inner loop converged at iteration 0\n",
      "f(x, y) = 76.90373654983917, grad_norm = 0.0088194864490811\n",
      "Outer iteration 73\n",
      "Inner loop converged at iteration 0\n",
      "f(x, y) = 76.90373691747283, grad_norm = 0.0077813319849145725\n",
      "Outer iteration 74\n",
      "Inner loop converged at iteration 0\n",
      "f(x, y) = 76.90373814486682, grad_norm = 0.0068642852448832755\n",
      "Outer iteration 75\n",
      "Inner loop converged at iteration 0\n",
      "f(x, y) = 76.90374009514098, grad_norm = 0.006054273616333817\n",
      "Outer iteration 76\n",
      "Inner loop converged at iteration 0\n",
      "f(x, y) = 76.90374264772755, grad_norm = 0.005338859741470696\n",
      "Outer iteration 77\n",
      "Inner loop converged at iteration 0\n",
      "f(x, y) = 76.90374569662887, grad_norm = 0.004707051098540946\n",
      "Outer iteration 78\n",
      "Inner loop converged at iteration 0\n",
      "f(x, y) = 76.90374914885479, grad_norm = 0.004149131833070435\n",
      "Outer iteration 79\n",
      "Inner loop converged at iteration 0\n",
      "f(x, y) = 76.90375292301869, grad_norm = 0.003656514228698158\n",
      "Outer iteration 80\n",
      "Inner loop converged at iteration 0\n",
      "f(x, y) = 76.90375694807787, grad_norm = 0.0032216075145026692\n",
      "Outer iteration 81\n",
      "Inner loop converged at iteration 0\n",
      "f(x, y) = 76.90376116220183, grad_norm = 0.0028377019772214307\n",
      "Outer iteration 82\n",
      "Inner loop converged at iteration 0\n",
      "f(x, y) = 76.90376551175629, grad_norm = 0.002498866585738843\n",
      "Outer iteration 83\n",
      "Inner loop converged at iteration 0\n",
      "f(x, y) = 76.90376995039117, grad_norm = 0.0021998585463053806\n",
      "Outer iteration 84\n",
      "Inner loop converged at iteration 0\n",
      "f(x, y) = 76.90377443822182, grad_norm = 0.0019360433928156421\n",
      "Outer iteration 85\n",
      "Inner loop converged at iteration 0\n",
      "f(x, y) = 76.90377894109494, grad_norm = 0.0017033243803769378\n",
      "Outer iteration 86\n",
      "Inner loop converged at iteration 0\n",
      "f(x, y) = 76.90378342993006, grad_norm = 0.001498080095144775\n",
      "Outer iteration 87\n",
      "Inner loop converged at iteration 0\n",
      "f(x, y) = 76.90378788012967, grad_norm = 0.0013171093208255373\n",
      "Outer iteration 88\n",
      "Inner loop converged at iteration 0\n",
      "f(x, y) = 76.90379227105093, grad_norm = 0.0011575823151035029\n",
      "Outer iteration 89\n",
      "Inner loop converged at iteration 0\n",
      "f(x, y) = 76.90379658553304, grad_norm = 0.0010169977476968696\n",
      "Outer iteration 90\n",
      "Inner loop converged at iteration 0\n",
      "Outer loop converged at iteration 89\n",
      "Optimized x: [-0.0085159   0.0776357  -0.00555323 -0.00577477 -0.00499069 -0.01099207\n",
      "  0.06908659  0.01461562  0.13609345  0.18906086  0.00813051 -0.08934281\n",
      "  0.00661051  0.17644495  0.02921803  0.09046036 -0.04726841  0.12689131\n",
      " -0.04575297 -0.1089336  -0.08293173 -0.10580643  0.00363092 -0.02657722\n",
      " -0.05726623 -0.01635785 -0.05038452 -0.06889859 -0.10724418  0.02613295\n",
      " -0.03526874 -0.10083589 -0.1338412   0.02898518 -0.05438005 -0.14009519\n",
      "  0.02451386  0.01413073 -0.04526563 -0.09209226 -0.11634284 -0.00360421\n",
      " -0.03660255 -0.04979769  0.10128189 -0.00664601 -0.01065036  0.0808761\n",
      " -0.13526989  0.02395797  0.18150238  0.17196167  0.02188577  0.06743527\n",
      "  0.09204189 -0.00618419 -0.06035156 -0.04020514 -0.03547661  0.0821776 ]\n",
      "Optimized y: [-0.09290896  0.03451292 -0.02373756 -0.01925836 -0.04494894  0.12253554\n",
      " -0.08600141 -0.20189954 -0.47681637 -0.08956265  0.02979375 -0.13022445\n",
      " -0.17642903  0.15216015  0.02117895  0.29159506  0.10293246 -0.06412957\n",
      "  0.27236281 -0.26027048 -0.21451611 -0.14898698 -0.02690145 -0.15972822\n",
      "  0.15156054  0.0637199  -0.302615    0.05653116  0.16631634 -0.23223718\n",
      "  0.12389959 -0.12884781  0.16097791  0.36233671 -0.10740931  0.11762344\n",
      " -0.1268399  -0.0163963  -0.10158541  0.14301083  0.07336305 -0.0536643\n",
      " -0.20493801  0.14014547 -0.39012223 -0.33989264  0.18413401  0.02831696\n",
      " -0.03156601 -0.31189134 -0.04572605  0.13728062  0.04117082 -0.05570376\n",
      " -0.08121643  0.05924641 -0.13093852  0.02532283  0.13892868  0.21032291]\n",
      "\n",
      "Values of h_1 constraints at the optimal point:\n",
      "h_1[0] = -1.818606806017621\n",
      "h_1[1] = -0.6332653285456722\n",
      "h_1[2] = 0.692060467876725\n",
      "h_1[3] = -0.19201660481909777\n",
      "h_1[4] = -0.600298040133991\n",
      "h_1[5] = -0.2737396315591377\n",
      "h_1[6] = -1.012366935480417\n",
      "h_1[7] = 0.4450296606186358\n",
      "h_1[8] = -1.4287421110645298\n",
      "h_1[9] = -0.8173446049192401\n",
      "h_1[10] = 1.0874902560609827\n",
      "h_1[11] = -1.4789022155643556\n",
      "h_1[12] = 0.10827124470942368\n",
      "h_1[13] = -1.786263928772887\n",
      "h_1[14] = -0.8903993418731315\n",
      "h_1[15] = -0.07504978497512865\n",
      "h_1[16] = -0.3015547409733911\n",
      "h_1[17] = -0.21462543837571568\n",
      "h_1[18] = -0.693290361744195\n",
      "h_1[19] = 0.5416734352752851\n"
     ]
    }
   ],
   "source": [
    "IGD_algo = IGD(problem, hparams)\n",
    "\n",
    "x_opt_IGD, y_opt_IGD, history = IGD_algo.upper_loop(x_init, y_init)\n",
    "\n",
    "print(\"Optimized x:\", x_opt_IGD)\n",
    "print(\"Optimized y:\", y_opt_IGD)\n",
    "\n",
    "h1_values = [problem.h_1(x_opt_IGD, y_opt_IGD, i) for i in range(problem.num_constraints_h1)]\n",
    "\n",
    "print(\"\\nValues of h_1 constraints at the optimal point:\")\n",
    "for i, h_val in enumerate(h1_values):\n",
    "    print(f\"h_1[{i}] = {h_val}\")\n",
    "\n",
    "times = [h['time'] for h in history]\n",
    "grad_norms = [h['grad_norm'] for h in history]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implicit Gradient Descent Feasibility Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_theoretical_opt_result=59.04726374415966, f_IGD_numerical_result=76.90380080947456\n",
      "g_theoretical_opt_result=-47.905074255466786, g_IGD_numerical_result=-51.811093935401786\n",
      "h_1[0] = -1.818606806017621\n",
      "h_1[1] = -0.6332653285456722\n",
      "h_1[2] = 0.692060467876725\n",
      "h_1[3] = -0.19201660481909777\n",
      "h_1[4] = -0.600298040133991\n",
      "h_1[5] = -0.2737396315591377\n",
      "h_1[6] = -1.012366935480417\n",
      "h_1[7] = 0.4450296606186358\n",
      "h_1[8] = -1.4287421110645298\n",
      "h_1[9] = -0.8173446049192401\n",
      "h_1[10] = 1.0874902560609827\n",
      "h_1[11] = -1.4789022155643556\n",
      "h_1[12] = 0.10827124470942368\n",
      "h_1[13] = -1.786263928772887\n",
      "h_1[14] = -0.8903993418731315\n",
      "h_1[15] = -0.07504978497512865\n",
      "h_1[16] = -0.3015547409733911\n",
      "h_1[17] = -0.21462543837571568\n",
      "h_1[18] = -0.693290361744195\n",
      "h_1[19] = 0.5416734352752851\n",
      "h_2[0] = -1.0929089554460576\n",
      "h_2[1] = -0.9654870816489937\n",
      "h_2[2] = -1.0237375559765334\n",
      "h_2[3] = -1.0192583555543342\n",
      "h_2[4] = -1.044948936664087\n",
      "h_2[5] = -0.877464459734365\n",
      "h_2[6] = -1.0860014094637798\n",
      "h_2[7] = -1.2018995373962\n",
      "h_2[8] = -1.4768163650099424\n",
      "h_2[9] = -1.0895626530177402\n",
      "h_2[10] = -0.9702062530189746\n",
      "h_2[11] = -1.1302244537316852\n",
      "h_2[12] = -1.1764290341975174\n",
      "h_2[13] = -0.8478398519709273\n",
      "h_2[14] = -0.9788210468896923\n",
      "h_2[15] = -0.7084049398982791\n",
      "h_2[16] = -0.8970675419302193\n",
      "h_2[17] = -1.0641295664574952\n",
      "h_2[18] = -0.7276371859940222\n",
      "h_2[19] = -1.2602704823813948\n",
      "h_2[20] = -1.214516110318993\n",
      "h_2[21] = -1.1489869809436168\n",
      "h_2[22] = -1.0269014468132798\n",
      "h_2[23] = -1.1597282171303938\n",
      "h_2[24] = -0.8484394577178922\n",
      "h_2[25] = -0.936280100940169\n",
      "h_2[26] = -1.3026150022121294\n",
      "h_2[27] = -0.9434688428195299\n",
      "h_2[28] = -0.8336836564958827\n",
      "h_2[29] = -1.2322371846881393\n",
      "h_2[30] = -0.8761004133042183\n",
      "h_2[31] = -1.1288478128038268\n",
      "h_2[32] = -0.8390220850687464\n",
      "h_2[33] = -0.6376632924019874\n",
      "h_2[34] = -1.1074093071472695\n",
      "h_2[35] = -0.8823765561350587\n",
      "h_2[36] = -1.126839903642242\n",
      "h_2[37] = -1.0163962953552648\n",
      "h_2[38] = -1.1015854082895646\n",
      "h_2[39] = -0.856989167560429\n",
      "h_2[40] = -0.9266369544231609\n",
      "h_2[41] = -1.0536643015359095\n",
      "h_2[42] = -1.2049380104367522\n",
      "h_2[43] = -0.8598545339901604\n",
      "h_2[44] = -1.3901222283489099\n",
      "h_2[45] = -1.3398926378717777\n",
      "h_2[46] = -0.8158659873037313\n",
      "h_2[47] = -0.9716830425724646\n",
      "h_2[48] = -1.0315660056364464\n",
      "h_2[49] = -1.3118913365126021\n",
      "h_2[50] = -1.0457260509433128\n",
      "h_2[51] = -0.8627193804922955\n",
      "h_2[52] = -0.9588291796141162\n",
      "h_2[53] = -1.0557037631448931\n",
      "h_2[54] = -1.0812164260110504\n",
      "h_2[55] = -0.940753586023736\n",
      "h_2[56] = -1.1309385194784598\n",
      "h_2[57] = -0.97467716964067\n",
      "h_2[58] = -0.8610713151871046\n",
      "h_2[59] = -0.789677088191885\n",
      "h_2[60] = -0.9070910445539423\n",
      "h_2[61] = -1.0345129183510064\n",
      "h_2[62] = -0.9762624440234666\n",
      "h_2[63] = -0.9807416444456657\n",
      "h_2[64] = -0.955051063335913\n",
      "h_2[65] = -1.122535540265635\n",
      "h_2[66] = -0.9139985905362202\n",
      "h_2[67] = -0.7981004626038001\n",
      "h_2[68] = -0.5231836349900576\n",
      "h_2[69] = -0.9104373469822599\n",
      "h_2[70] = -1.0297937469810254\n",
      "h_2[71] = -0.8697755462683148\n",
      "h_2[72] = -0.8235709658024826\n",
      "h_2[73] = -1.1521601480290729\n",
      "h_2[74] = -1.0211789531103077\n",
      "h_2[75] = -1.291595060101721\n",
      "h_2[76] = -1.1029324580697806\n",
      "h_2[77] = -0.9358704335425048\n",
      "h_2[78] = -1.272362814005978\n",
      "h_2[79] = -0.7397295176186052\n",
      "h_2[80] = -0.7854838896810069\n",
      "h_2[81] = -0.851013019056383\n",
      "h_2[82] = -0.9730985531867201\n",
      "h_2[83] = -0.8402717828696062\n",
      "h_2[84] = -1.1515605422821078\n",
      "h_2[85] = -1.0637198990598309\n",
      "h_2[86] = -0.6973849977878706\n",
      "h_2[87] = -1.05653115718047\n",
      "h_2[88] = -1.1663163435041173\n",
      "h_2[89] = -0.7677628153118607\n",
      "h_2[90] = -1.1238995866957817\n",
      "h_2[91] = -0.8711521871961732\n",
      "h_2[92] = -1.1609779149312536\n",
      "h_2[93] = -1.3623367075980126\n",
      "h_2[94] = -0.8925906928527306\n",
      "h_2[95] = -1.1176234438649413\n",
      "h_2[96] = -0.8731600963577579\n",
      "h_2[97] = -0.9836037046447352\n",
      "h_2[98] = -0.8984145917104355\n",
      "h_2[99] = -1.143010832439571\n",
      "h_2[100] = -1.0733630455768393\n",
      "h_2[101] = -0.9463356984640905\n",
      "h_2[102] = -0.7950619895632478\n",
      "h_2[103] = -1.1401454660098396\n",
      "h_2[104] = -0.6098777716510903\n",
      "h_2[105] = -0.6601073621282223\n",
      "h_2[106] = -1.1841340126962687\n",
      "h_2[107] = -1.0283169574275355\n",
      "h_2[108] = -0.9684339943635535\n",
      "h_2[109] = -0.6881086634873979\n",
      "h_2[110] = -0.9542739490566873\n",
      "h_2[111] = -1.1372806195077045\n",
      "h_2[112] = -1.0411708203858838\n",
      "h_2[113] = -0.9442962368551069\n",
      "h_2[114] = -0.9187835739889496\n",
      "h_2[115] = -1.059246413976264\n",
      "h_2[116] = -0.8690614805215402\n",
      "h_2[117] = -1.02532283035933\n",
      "h_2[118] = -1.1389286848128954\n",
      "h_2[119] = -1.210322911808115\n"
     ]
    }
   ],
   "source": [
    "barrier_algo = BarrierBLO(problem, hparams)\n",
    "\n",
    "h1_values = [problem.h_1(x_opt_IGD, y_opt_IGD, i) for i in range(problem.num_constraints_h1)]\n",
    "h2_values = [problem.h_2(x_opt_IGD, y_opt_IGD, i) for i in range(problem.num_constraints_h2)]\n",
    "\n",
    "y_original_opt_IGD = barrier_algo.Interior_inner_loop(x_opt_IGD, y_opt_IGD)\n",
    "print(f\"f_theoretical_opt_result={problem.f(x_opt_IGD, y_original_opt_IGD)}, f_IGD_numerical_result={problem.f(x_opt_IGD, y_opt_IGD)}\")\n",
    "\n",
    "print(f\"g_theoretical_opt_result={problem.g(x_opt_IGD, y_original_opt_IGD)}, g_IGD_numerical_result={problem.g(x_opt_IGD, y_opt_IGD)}\")\n",
    "\n",
    "for i, h_val in enumerate(h1_values):\n",
    "    print(f\"h_1[{i}] = {h_val}\")\n",
    "\n",
    "for i, h_val in enumerate(h2_values):\n",
    "    print(f\"h_2[{i}] = {h_val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BFBM Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer iteration 1\n",
      "Inner loop converged at iteration 84\n",
      "f(x, y) = 77.1715615837633, grad_norm of hyperfunction= 87.45817064272863\n",
      "Outer iteration 2\n",
      "Inner loop converged at iteration 74\n",
      "f(x, y) = 78.90024953534076, grad_norm of hyperfunction= 392.8141925153819\n",
      "Outer iteration 3\n",
      "Inner loop converged at iteration 90\n",
      "f(x, y) = 29.23452608787925, grad_norm of hyperfunction= 150.63346563071727\n",
      "Outer iteration 4\n",
      "Inner loop converged at iteration 85\n",
      "f(x, y) = 13.444898881685411, grad_norm of hyperfunction= 102.62089018132221\n",
      "Outer iteration 5\n",
      "Inner loop converged at iteration 84\n",
      "f(x, y) = 7.4682148832218616, grad_norm of hyperfunction= 76.75084902098465\n",
      "Outer iteration 6\n",
      "Inner loop converged at iteration 80\n",
      "f(x, y) = 3.8799643720035704, grad_norm of hyperfunction= 64.7094077398494\n",
      "Outer iteration 7\n",
      "Inner loop converged at iteration 80\n",
      "f(x, y) = 1.3128754379971141, grad_norm of hyperfunction= 55.90741593897381\n",
      "Outer iteration 8\n",
      "Inner loop converged at iteration 80\n",
      "f(x, y) = -0.6132860446946751, grad_norm of hyperfunction= 47.573307995877144\n",
      "Outer iteration 9\n",
      "Inner loop converged at iteration 83\n",
      "f(x, y) = -1.9128110239262597, grad_norm of hyperfunction= 39.66673228828804\n",
      "Outer iteration 10\n",
      "Inner loop converged at iteration 79\n",
      "f(x, y) = -2.8503102816991053, grad_norm of hyperfunction= 32.748361433185195\n",
      "Outer iteration 11\n",
      "Inner loop converged at iteration 77\n",
      "f(x, y) = -3.3697582740773377, grad_norm of hyperfunction= 27.65926546606435\n",
      "Outer iteration 12\n",
      "Inner loop converged at iteration 71\n",
      "f(x, y) = -3.895662151395854, grad_norm of hyperfunction= 26.310524992650173\n",
      "Outer iteration 13\n",
      "Inner loop converged at iteration 82\n",
      "f(x, y) = -3.847001625094677, grad_norm of hyperfunction= 34.75902472678869\n",
      "Outer iteration 14\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[96], line 13\u001b[0m\n\u001b[0;32m      1\u001b[0m barrier_algo \u001b[38;5;241m=\u001b[39m BarrierBLO(problem, hparams)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# y_proj = barrier_algo.project_to_constraints(x_init, y_init)\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# h = problem.h_1(x_init, y_proj, 0)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m \n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# print(h)\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m x_opt_barrier, y_opt_barrier, history \u001b[38;5;241m=\u001b[39m \u001b[43mbarrier_algo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupper_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_init\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_init\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimized x:\u001b[39m\u001b[38;5;124m\"\u001b[39m, x_opt_barrier)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimized y:\u001b[39m\u001b[38;5;124m\"\u001b[39m, y_opt_barrier)\n",
      "File \u001b[1;32md:\\study_work\\project\\bilevel_ipm\\generated_problem\\algorithms\\barrier_blo_box.py:572\u001b[0m, in \u001b[0;36mBarrierBLO.upper_loop\u001b[1;34m(self, x_init, y_init)\u001b[0m\n\u001b[0;32m    570\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m outer_iter \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mouter_max_iters):\n\u001b[0;32m    571\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOuter iteration \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mouter_iter\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 572\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minner_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    573\u001b[0m     grad_f_x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproblem\u001b[38;5;241m.\u001b[39mgradient_f_x(x, y)\n\u001b[0;32m    574\u001b[0m     grad_f_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproblem\u001b[38;5;241m.\u001b[39mgradient_f_y(x, y)\n",
      "File \u001b[1;32md:\\study_work\\project\\bilevel_ipm\\generated_problem\\algorithms\\barrier_blo_box.py:354\u001b[0m, in \u001b[0;36mBarrierBLO.inner_loop\u001b[1;34m(self, x, y_init)\u001b[0m\n\u001b[0;32m    352\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInner loop converged at iteration \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28miter\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    353\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 354\u001b[0m Hessian_yy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhessian_tilde_g_yy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    356\u001b[0m     v \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39msolve(Hessian_yy, grad_y)\n",
      "File \u001b[1;32md:\\study_work\\project\\bilevel_ipm\\generated_problem\\algorithms\\barrier_blo_box.py:109\u001b[0m, in \u001b[0;36mBarrierBLO.hessian_tilde_g_yy\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhessian_tilde_g_yy\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, y):\n\u001b[0;32m    108\u001b[0m     hessian_g_yy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproblem\u001b[38;5;241m.\u001b[39mhessian_g_yy(x, y)\n\u001b[1;32m--> 109\u001b[0m     sum_constraints \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproblem\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproblem\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    110\u001b[0m     t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mt\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproblem\u001b[38;5;241m.\u001b[39mnum_constraints_h1):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "barrier_algo = BarrierBLO(problem, hparams)\n",
    "\n",
    "# y_proj = barrier_algo.project_to_constraints(x_init, y_init)\n",
    "\n",
    "# h = problem.h_1(x_init, y_proj, 0)\n",
    "\n",
    "# print(y_proj)\n",
    "\n",
    "# print(h)\n",
    "\n",
    "\n",
    "\n",
    "x_opt_barrier, y_opt_barrier, history = barrier_algo.upper_loop(x_init, y_init)\n",
    "\n",
    "print(\"Optimized x:\", x_opt_barrier)\n",
    "print(\"Optimized y:\", y_opt_barrier)\n",
    "\n",
    "h1_values = [problem.h_1(x_opt_barrier, y_opt_barrier, i) for i in range(problem.num_constraints_h1)]\n",
    "\n",
    "print(\"\\nValues of h_1 constraints at the optimal point:\")\n",
    "for i, h_val in enumerate(h1_values):\n",
    "    print(f\"h_1[{i}] = {h_val}\")\n",
    "\n",
    "times = [h['time'] for h in history]\n",
    "grad_norms = [h['grad_norm'] for h in history]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_theoretical_opt_result=-15.306563751288039, f_bfbm_numerical_result=-15.153427501682827\n",
      "g_theoretical_opt_result=-24.423517710938498, g_bfbm_numerical_result=-24.333709631271457\n",
      "h_1[0] = -0.8530995669552834\n",
      "h_1[1] = -0.2613523576031589\n",
      "h_1[2] = -0.001278392080932278\n",
      "h_1[3] = -0.07502091218352613\n",
      "h_1[4] = -0.375177649114236\n",
      "h_1[5] = -0.049867996945927556\n",
      "h_1[6] = -0.8780341222931158\n",
      "h_1[7] = -0.0014893580201749135\n",
      "h_1[8] = -0.5236765700613755\n",
      "h_1[9] = -0.6984091586204063\n",
      "h_1[10] = -0.00157056475541284\n",
      "h_1[11] = -0.44529108173842336\n",
      "h_1[12] = -0.013355775506502299\n",
      "h_1[13] = -1.1743797753157472\n",
      "h_1[14] = -0.760361498677131\n",
      "h_1[15] = -0.00692658288940684\n",
      "h_1[16] = -1.1122354621821224\n",
      "h_1[17] = -0.0022449890145965767\n",
      "h_1[18] = -0.003619708732381821\n",
      "h_1[19] = -0.0012898782281610122\n",
      "h_2[0] = -1.0393108199461274\n",
      "h_2[1] = -1.0373869892836591\n",
      "h_2[2] = -0.9414777455098461\n",
      "h_2[3] = -1.063995152673622\n",
      "h_2[4] = -1.0546833198897954\n",
      "h_2[5] = -0.9322605401319755\n",
      "h_2[6] = -0.9065338507107821\n",
      "h_2[7] = -1.0583022314748327\n",
      "h_2[8] = -1.1319367988648241\n",
      "h_2[9] = -1.0481441923007158\n",
      "h_2[10] = -0.9355200895077725\n",
      "h_2[11] = -1.015317157259212\n",
      "h_2[12] = -1.0799645627975776\n",
      "h_2[13] = -1.0579361377007057\n",
      "h_2[14] = -1.019849506842515\n",
      "h_2[15] = -0.8335154330135564\n",
      "h_2[16] = -0.919266598861149\n",
      "h_2[17] = -1.0757859949714372\n",
      "h_2[18] = -0.8806383921132668\n",
      "h_2[19] = -1.04665794575399\n",
      "h_2[20] = -1.0641502225052752\n",
      "h_2[21] = -1.0749413453275782\n",
      "h_2[22] = -0.8704656754107324\n",
      "h_2[23] = -1.100116169401721\n",
      "h_2[24] = -1.0097044878492079\n",
      "h_2[25] = -1.00795241069766\n",
      "h_2[26] = -1.0610081953038415\n",
      "h_2[27] = -1.0212008175930172\n",
      "h_2[28] = -0.8896438031591943\n",
      "h_2[29] = -1.061680981352364\n",
      "h_2[30] = -0.972934371970629\n",
      "h_2[31] = -1.0512062287395214\n",
      "h_2[32] = -0.9389570970668266\n",
      "h_2[33] = -0.9027310715862262\n",
      "h_2[34] = -1.050167389741062\n",
      "h_2[35] = -0.9167597442868918\n",
      "h_2[36] = -1.0092312590260015\n",
      "h_2[37] = -1.0601902622347574\n",
      "h_2[38] = -1.059523701347752\n",
      "h_2[39] = -0.9180653903081475\n",
      "h_2[40] = -0.9427635319322291\n",
      "h_2[41] = -1.0271479553229494\n",
      "h_2[42] = -1.045863497408097\n",
      "h_2[43] = -0.94352319191754\n",
      "h_2[44] = -1.102824212880726\n",
      "h_2[45] = -1.0931666769842858\n",
      "h_2[46] = -0.931998321798472\n",
      "h_2[47] = -0.9497823201504998\n",
      "h_2[48] = -0.9256736483256138\n",
      "h_2[49] = -1.137458465057773\n",
      "h_2[50] = -0.9911124678014571\n",
      "h_2[51] = -0.9776227921445081\n",
      "h_2[52] = -1.002158951165092\n",
      "h_2[53] = -1.0913286371372986\n",
      "h_2[54] = -1.032242036517142\n",
      "h_2[55] = -0.9536208176377091\n",
      "h_2[56] = -1.0197314269095574\n",
      "h_2[57] = -0.9559405585846967\n",
      "h_2[58] = -0.8519828660263543\n",
      "h_2[59] = -0.9274227731080398\n",
      "h_2[60] = -0.9606891800538726\n",
      "h_2[61] = -0.9626130107163408\n",
      "h_2[62] = -1.0585222544901538\n",
      "h_2[63] = -0.936004847326378\n",
      "h_2[64] = -0.9453166801102046\n",
      "h_2[65] = -1.0677394598680245\n",
      "h_2[66] = -1.093466149289218\n",
      "h_2[67] = -0.9416977685251673\n",
      "h_2[68] = -0.8680632011351759\n",
      "h_2[69] = -0.9518558076992841\n",
      "h_2[70] = -1.0644799104922273\n",
      "h_2[71] = -0.9846828427407881\n",
      "h_2[72] = -0.9200354372024224\n",
      "h_2[73] = -0.9420638622992944\n",
      "h_2[74] = -0.9801504931574849\n",
      "h_2[75] = -1.1664845669864436\n",
      "h_2[76] = -1.080733401138851\n",
      "h_2[77] = -0.9242140050285628\n",
      "h_2[78] = -1.1193616078867332\n",
      "h_2[79] = -0.95334205424601\n",
      "h_2[80] = -0.9358497774947246\n",
      "h_2[81] = -0.9250586546724218\n",
      "h_2[82] = -1.1295343245892675\n",
      "h_2[83] = -0.8998838305982791\n",
      "h_2[84] = -0.9902955121507921\n",
      "h_2[85] = -0.9920475893023398\n",
      "h_2[86] = -0.9389918046961585\n",
      "h_2[87] = -0.9787991824069827\n",
      "h_2[88] = -1.1103561968408058\n",
      "h_2[89] = -0.938319018647636\n",
      "h_2[90] = -1.0270656280293708\n",
      "h_2[91] = -0.9487937712604787\n",
      "h_2[92] = -1.0610429029331734\n",
      "h_2[93] = -1.0972689284137738\n",
      "h_2[94] = -0.9498326102589382\n",
      "h_2[95] = -1.0832402557131082\n",
      "h_2[96] = -0.9907687409739985\n",
      "h_2[97] = -0.9398097377652427\n",
      "h_2[98] = -0.9404762986522478\n",
      "h_2[99] = -1.0819346096918525\n",
      "h_2[100] = -1.0572364680677708\n",
      "h_2[101] = -0.9728520446770504\n",
      "h_2[102] = -0.954136502591903\n",
      "h_2[103] = -1.05647680808246\n",
      "h_2[104] = -0.8971757871192739\n",
      "h_2[105] = -0.9068333230157142\n",
      "h_2[106] = -1.068001678201528\n",
      "h_2[107] = -1.0502176798495002\n",
      "h_2[108] = -1.0743263516743862\n",
      "h_2[109] = -0.862541534942227\n",
      "h_2[110] = -1.0088875321985429\n",
      "h_2[111] = -1.0223772078554918\n",
      "h_2[112] = -0.9978410488349082\n",
      "h_2[113] = -0.9086713628627016\n",
      "h_2[114] = -0.9677579634828579\n",
      "h_2[115] = -1.046379182362291\n",
      "h_2[116] = -0.9802685730904425\n",
      "h_2[117] = -1.0440594414153033\n",
      "h_2[118] = -1.1480171339736458\n",
      "h_2[119] = -1.0725772268919602\n"
     ]
    }
   ],
   "source": [
    "barrier_algo = BarrierBLO(problem, hparams)\n",
    "\n",
    "h1_values = [problem.h_1(x_opt_barrier, y_opt_barrier, i) for i in range(problem.num_constraints_h1)]\n",
    "h2_values = [problem.h_2(x_opt_barrier, y_opt_barrier, i) for i in range(problem.num_constraints_h2)]\n",
    "\n",
    "y_original_opt_bfbm = barrier_algo.Interior_inner_loop(x_opt_barrier, y_opt_barrier)\n",
    "print(f\"f_theoretical_opt_result={problem.f(x_opt_barrier, y_original_opt_bfbm)}, f_bfbm_numerical_result={problem.f(x_opt_barrier, y_opt_barrier)}\")\n",
    "\n",
    "print(f\"g_theoretical_opt_result={problem.g(x_opt_barrier, y_original_opt_bfbm)}, g_bfbm_numerical_result={problem.g(x_opt_barrier, y_opt_barrier)}\")\n",
    "\n",
    "for i, h_val in enumerate(h1_values):\n",
    "    print(f\"h_1[{i}] = {h_val}\")\n",
    "\n",
    "for i, h_val in enumerate(h2_values):\n",
    "    print(f\"h_2[{i}] = {h_val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(times, grad_norms, marker='o', markersize=1)\n",
    "plt.xlabel('CPU Time (s)')\n",
    "plt.ylabel('Gradient Norm')\n",
    "plt.title('Gradient Norm vs CPU Time')\n",
    "plt.yscale('log')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BLO",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
